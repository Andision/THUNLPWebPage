{
    "language": "en",
    "wyzs": "CUGE",
    "app_Tasks": "Framework",
    "app_Leaderboard": "Leaderboard",
    "app_FAQ": "FAQ",
    "app_Paper": "Paper",
    "app_Submit": "Submit",
    "app_Download": "Dataset",
    "app_About": "About",
    "app_User": "Profile",
    "app_Logout": "Logout",
    "app_Single": "Single",
    "datadownload_task": "Ability | Task",
    "reset_confirmPswd":"Confirm Password",
    "reset_pswd":"Input Password",
    "reset_reset": "Reset",
    "home_title1": "CUGE",
    "home_title2": "Chinese Language Understanding and Generation Evaluation Benchmark",
    "home_titledetail": "CUGE contains high-quality Chinese natural language processing datasets, leaderboard and online evaluation platform. CUGE aims to build a comprehensive and systematic Chinese language intelligence evaluation system, form a multi-level evaluation strategy, and promote the standard evaluation of Chinese natural language processing technology in a more scientific, standardized and high-quality manner.",
    "home_secondtitle": "委员单位 | Organizations",
    "leaderboard_phb": "Leaderboard",
    "leaderboard_yyljcy": "NLU-WSL",
    "leaderboard_yyljpj": "NLU-DL",
    "leaderboard_xxhq": "IA&QA",
    "leaderboard_yysc": "NLG",
    "leaderboard_dhjh": "CI",
    "leaderboard_dyy": "ML",
    "leaderboard_sxtl": "MR",
    "leaderboard_zyzs": "CUGE Index",
    "leaderboard_rank": "Rank",
    "leaderboard_model": "Model",
    "leaderboard_org": "Org",
    "leaderboard_codepaper": "Code | Paper",
    "leaderboard_submittime": "Time",
    "leaderboard_yyljcy_hint": "Language Understanding: Word-Sentence Level",
    "leaderboard_yyljpj_hint": "Language Understanding: Discourse Level",
    "leaderboard_xxhq_hint": "Information Acquisition and Question Answering",
    "leaderboard_yysc_hint": "Language Generation",
    "leaderboard_dhjh_hint": "Conversational Interaction",
    "leaderboard_dyy_hint": "Multilingualism",
    "leaderboard_sxtl_hint": "Mathematical Reasoning",
    "leaderboard_zyzs_hint": "CUGE Index based on mT5-small",
    "submit_org": "Organization",
    "about_title": "ABOUT US",
    "about_title1": "About Us",
    "about_title2": "Work Committee",
    "about_title3": "Committee Organization",
    "about_title4": "R&D Team",
    "about_pic": "https://z3.ax1x.com/2021/09/16/4uSfAO.png",
    "about_list": [
        "Tsinghua Natural Language Processing and Computational Social Science Lab",
        "Peking University Institute of Computational Linguistics",
        "Tsinghua Knowledge Engineering Group",
        "Wangxuan Institute of Computer Technology, Peking University",
        "Gaoling School of Artificial Intelligence,Renmin University of China",
        "National Laboratory of Pattern Recognition, Institute of Automation,Chinese Academy of Sciences",
        "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences",
        "Beijing Advanced Innovation Center for Language Resources, Beijing Language and Culture University",
        "JD AI Research",
        "Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology",
        "Conversational AI, Tsinghua University",
        "The Fudan University Natural Language Processing Group",
        "Institute of Human Language Technology, Soochow University",
        "Dalian University of Technology Information Retrieval",
        "Key Laboratory Computational Intelligence and Chinese Information Processing of Ministry of Education, Shanxi University"
    ],
    "about_content1": "The CUGE benchmark is built with the support of Beijing Academy of Artificial Intelligence, and the committee organizations are composed of 15 domestic superior research institutes. CUGE aims to build a comprehensive and systematic Chinese language intelligence evaluation system, form a multi-level evaluation strategy, and promote the standard evaluation of Chinese natural language processing technology in a more scientific, standardized and high-quality manner.",
    "user_code": "Code Link",
    "user_paper": "Paper Link",
    "user_submit": "Submit",
    "user_operation": "Operation",
    "user_delete": "Delete",
    "user_edit": "Edit Links",
    "user_check": "In Review",
    "user_public": "Disclosure",
    "user_accepted": "Accepted",
    "user_rejected": "Rejected",
    "moreinfo_org": "Organization",
    "moreinfo_author": "Author",
    "faq_content": [
        {
            "title": "How to participate in CUGE evaluation?",
            "details": [
                "Download all datasets on the introduction page of CUGE framework, or download a specific dataset on the data download page.",
                "Generate the prediction result file of the test set. The format of the prediction result file is defined in the README file of the corresponding dataset.",
                "Name the prediction result file according to the correct submission file name required in the README file of the corresponding dataset and compress it into a zip format. Log in to your personal account and submit it on the Submit page."
            ]
        },
        {
            "title": "How does the leaderboard of CUGE work?",
            "details": [
                "CUGE leaderboard adopts a multi-level scoring strategy. Based on the 'capability-task-dataset' framework, the leaderboard calculates the scores of each dataset, task, capability, as well as the overall CUGE Index score recursively from the bottom up, by averaging the scores of current level.",
                "In order to eliminate the differences between different datasets and evaluation metrics, the CUGE Index normalizes each evaluation metric score of the participating models, based on the scores of the standard baseline model (mT5-small), and then calculates the scores of each level from the bottom up (shown in parentheses in the leaderboard)."
            ]
        },
        {
            "title": "What rules need to be followed to participate in the evaluation?",
            "details": [
                "It is prohibited to use test set label information in model training and submission results in any form, including manually labeling test set labels.",
                "It is encouraged to share the papers/technical reports/codes to jointly promote the active and healthy development of the natural language processing community."
            ]
        },
        {
            "title": "How to download the dataset?",
            "details": [
                "All datasets can be downloaded with one click on the introduction page of CUGE framework.",
                "You can also download a specific dataset in the dataset list."
            ]
        },
        {
            "title": "What is the data usage license of CUGE?",
            "details": [
                "The data provided by CUGE is for individual research purposes only, and commercial use is prohibited."
            ]
        },
        {
            "title": "How to give feedback on CUGE?",
            "details": [
                "CUGE system and evaluation platform are still under continuous construction and improvement. We will open a user feedback forum in the CUGE community in the future."
            ],
            "pre": [
                "<div>For now, you can create issues at <a href='https://github.com/TsinghuaAI/CUGE'>CUGE</a> project on GitHub if you have any suggestions or comments for us.</div>"
            ]
        }
    ],
    "yes": "Yes",
    "no": "No",
    "hint_task": "Datasets in CUGE are principally selected and organized with a language capability-task-dataset hierarchy",
    "hint_yyljcy": "Evaluate the model's capability to understand a given text and perform word- and sentence-level syntactic and semantic tasks",
    "hint_yyljpj": "Evaluate the model's capability to understand a given text and perform discourse-level syntactic and semantic tasks",
    "hint_xxhq": "Evaluate the model's capability to obtain relevant information in open-domain corpora based on given queries",
    "hint_yysc": "Evaluate the model's capability to generate coherent text based on the given conditions",
    "hint_dhjh": "Evaluate the model's ability to generate appropriate conversation responses based on conversation history",
    "hint_dyy": "Evaluate the model's ability to perform tasks involving multiple languages",
    "hint_sxtl": "Evaluate the model's ability to abstract a given application scenario and perform mathematical computation tasks",
    "hint_leaderboard1": "The CUGE leaderboard adopts a multi-level scoring strategy, providing the scores of datasets, tasks, and capabilities, as well as an overall CUGE Index score.",
    "hint_leaderboard2": "CUGE normalizes the scores of participating models (shown in parentheses) based on the scores of the standard baseline model (mT5-small), maximally eliminating the differences between different datasets and evaluation metrics.",
    "submit_cycp": "Submit",
    "submit_hint": "Please make sure that you are submitting your prediction files with the structure of ability->task->dataset.",
    "submit_numOfPara": "Total number of parameters",
    "submit_paperLinks": "Paper Links",
    "submit_codeLinks": "Code Links",
    "submit_sfgk": "Pulibc?",
    "submit_sfyxl": "Pre-train model used?",
    "submit_sfjc": "Ensemble learning method used?",
    "submit_sfdrw": "Multi-task learning method used?",
    "submit_wlj": "I understand that it is prohibited to use manual test set label information in model training and submission results in any form.",
    "submit_tjcg": "Successfully Submit!",
    "user_submitRecord": "Submission Records",
    "task_xzsjj": "Download dataset",
    "task_synl": "All Capabilities",
    "sjxz": "数据下载",
    "notlogin": "The user is not logged in.",
    "gologin": "Do you want to login?",
    "more_intro": "Introduction",
    "more_paper": "Paper",
    "more_ref": "Paper Reference",
    "more_size": "Dataset Size",
    "more_download": "Dataset Download",
    "more_form": "Dataset Format Description",
    "more_sample": "Dataset Sample",
    "more_usage": "Usage",
    "task_sjnl": "识记能力",
    "task_ljnl": "理解能力",
    "task_jsnl": "检索能力",
    "task_szjsnl": "数值计算能力",
    "task_scnl": "生成能力",
    "task_dyynl": "多语言能力",
    "task_tj": "推荐",
    "task_nlb": "能力榜",
    "task_jjb": "Leaderboard",
    "task_wyzskj": "Framework",
    "forget_hint": "Please input your email, you will receive a mail with introduction.",
    "Tasks": "Tasks",
    "Leaderboard": "Leaderboard",
    "FAQ": "FAQ",
    "Paper": "Paper",
    "Submit": "Submit",
    "Download": "Download",
    "User": "User",
    "Logout": "Logout",
    "Username": "Username",
    "Email": "Email",
    "Password": "Password",
    "Login": "Login",
    "SignUp": "Sign Up",
    "Remeberme": "Remeber Me",
    "Forgetpassword": "Forget Password",
    "WelcomeToJoinUs": " ",
    "Notamember": "Not a member",
    "Alreadyhaveanaccount": "Already have an account",
    "PasswordAssistance": "Password Assistance",
    "Continue": "Continue",
    "or": "or",
    "Name": "Name",
    "Date": "Date",
    "Time": "Time",
    "Score": "Score",
    "Model": "Model",
    "Parameter": "Parameter",
    "More": "More",
    "Information": "Information",
    "Info": "Info",
    "Description": "Description",
    "Select": "Select",
    "Cancel": "Cancel"
}